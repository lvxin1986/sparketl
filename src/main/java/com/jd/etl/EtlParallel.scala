package com.jd.etl

import java.text.SimpleDateFormat
import java.util.concurrent.Executors
import java.util.{Calendar, Properties}

import com.jd.etl.consts.ETLConst
import com.jd.etl.utils.EtlUtil
import org.apache.spark.sql.{DataFrame, SparkSession}
import org.apache.spark.storage.StorageLevel

import scala.collection.mutable
import scala.concurrent._
import scala.concurrent.duration._
import scala.util.{Failure, Success}

/**
  * Created by root on 17-8-1.
  */
object EtlParallel {
  val hadoopConf = new org.apache.hadoop.conf.Configuration()
  val fs = org.apache.hadoop.fs.FileSystem.get(hadoopConf)
  val dateFormat = new SimpleDateFormat(ETLConst.ETL_DATE_FORMAT)
  var persistStatus: mutable.Map[String, Boolean] = collection.mutable.Map[String, Boolean]()

  def main(args: Array[String]) {

    if (args.length == 1) {
      initData(args(0))
    } else {
      etlDataDaily(args(0), args(1), args(2), args(3))
    }
    System.exit(0)
  }

/*
* initData
* 从多数据源抽取数据至未分区表
* */
  def initData(workSpace: String): Unit = {
    val spark = SparkSession.builder.appName("EtlParallel_Init_No_Partition").enableHiveSupport().getOrCreate

    var config = new EtlConfig(workSpace, spark)
    val pool = Executors.newFixedThreadPool(config.threadsNum)
    implicit val xc = ExecutionContext.fromExecutorService(pool)
    val tasks: mutable.MutableList[Future[String]] = mutable.MutableList[Future[String]]()
    val tblsArray: Array[String] = spark.sparkContext.textFile(workSpace + ETLConst.ETL_TABLELIST_FILE).collect()
    val schemasArray: Array[String] = spark.sparkContext.textFile(workSpace + ETLConst.ETL_SCHEMALIST_FILE).collect()
    val status: mutable.MutableList[String] = mutable.MutableList[String]()
    var schemaMap: Map[String, String] = EtlUtil.initSchemaMap(schemasArray)

    for (i <- 0 until tblsArray.length) {
      var tbSch: Array[String] = tblsArray.apply(i).split("\\s+")
      var tableName = tbSch.apply(0)
      var columns = schemaMap.apply(tbSch.apply(1))
      var sql: String = ""
      if (columns.equals("") || columns == null) {
        sql = "select * from " + tbSch.apply(0)
      } else {
        sql = "select " + columns + " from " + tbSch.apply(0)
      }

      val df = EtlUtil.castInt2BigInt(spark.sql(sql))
      df.persist(StorageLevel.MEMORY_AND_DISK_SER)

      if (EtlUtil.dirExists(fs, config.targetPath + tableName + "/_SUCCESS")) {
        println("[WARN]" + config.targetPath + tableName + "/_SUCCESS exist, skipped it")
      } else {
        if (EtlUtil.dirExists(fs, config.targetPath + tableName)) {
          println("[WARN]" + config.targetPath + tableName + " exist, but " + config.targetPath + tableName + "/_SUCCESS not exist,removing " + config.targetPath + tableName + " and reimport")
          fs.delete(new org.apache.hadoop.fs.Path(config.targetPath + tableName), true)
        }
        val task = doEtlPerTbl(df, null, config.targetPath + tableName, config.orcCoalesce)
        task.onComplete {
          case Success(result) =>
            println(s"result = $result")
            status += result
          case Failure(e) =>
            println(e.getMessage)
            status += e.getMessage
        }
        tasks += task
      }

    }

    Await.ready(Future.sequence(tasks), Duration(30, DAYS))
    println("[INFO] All Jobs has completed and the informations are:")
    for (i <- 0 until status.length) {
      println("[INFO]" + status(i))
    }
    spark.close()

  }

/*
* etlDataDaily
* 从单数据源抽取数据至分区表
* */
  def etlDataDaily(workSpace: String, filterCol: String, filterVal1: String, filterVal2: String): Unit = {
    val spark = SparkSession.builder.appName("EtlParallel_2_Orc_Daily") // optional and will be autogenerated if not specified
      .enableHiveSupport() // self-explanatory, isn't it?
      .getOrCreate

    var config = new EtlConfig(workSpace, spark)
    val tblsArray: Array[String] = spark.sparkContext.textFile(workSpace + ETLConst.ETL_TABLELIST_FILE).collect()
    val schemasArray: Array[String] = spark.sparkContext.textFile(workSpace + ETLConst.ETL_SCHEMALIST_FILE).collect()
    val pool = Executors.newFixedThreadPool(config.threadsNum)
    implicit val xc = ExecutionContext.fromExecutorService(pool)
    val tasks: mutable.MutableList[Future[String]] = mutable.MutableList[Future[String]]()
    val status: mutable.MutableList[String] = mutable.MutableList[String]()
    val schemaMap: Map[String, String] = EtlUtil.initSchemaMap(schemasArray)

    val tbl_schema_pair: Array[String] = tblsArray.apply(0).split("\\s+")
    val tblName = tbl_schema_pair.apply(0)
    persistStatus += (tblName -> false)
    val sql: String = EtlUtil.generateSql(schemaMap, tbl_schema_pair, filterCol, filterVal1, filterVal2)
    var df = EtlUtil.castInt2BigInt(spark.sql(sql))
    df = df.persist(StorageLevel.MEMORY_AND_DISK_SER)
    println("[INFO] execute the sql : " + sql + " and store in memory and disk!")
    val partitionCols = filterCol.split(",")
    for (j <- 0 until partitionCols.length) {
      val partition_col_name_type_pair = partitionCols.apply(j).split(":")
      val col_name = partition_col_name_type_pair.apply(0)
      val col_type = partition_col_name_type_pair.apply(1)
      var start_time = filterVal1.split(",").apply(j) + " 00:00:00"
      var end_time = filterVal2.split(",").apply(j) + " 00:00:00"

      var quotation = "";
      if (!ETLConst.COL_TYPE_NUMBER.contains(col_type.toUpperCase())) {
        quotation = "'"
      }
      while (!start_time.equals(end_time)) {//遍历配置日期，按天分区
        var cal: Calendar = Calendar.getInstance();
        cal.setTime(dateFormat.parse(end_time))
        cal.add(Calendar.DATE, -1)
        var yesterday = dateFormat.format(cal.getTime)
        val partitionPath = "/" + config.targetPartition + "=" + yesterday.substring(0, 10) + "/"
        val condition = col_name + ">=" + quotation + yesterday + quotation + " and " + col_name + "<" + quotation + end_time + quotation
        val totalPath = config.targetPath + config.targetTable + partitionPath

        if (EtlUtil.dirExists(fs, totalPath + "_SUCCESS")) {
          println("[WARN]" + totalPath + "_SUCCESS exist, skipped it")
        } else {
          if (EtlUtil.dirExists(fs, totalPath)) {
            println("[WARN]" + totalPath + " exist, but " + totalPath + "_SUCCESS not exist,removing " + totalPath + " and reimport")
            fs.delete(new org.apache.hadoop.fs.Path(totalPath), true)
          }
          if (persistStatus.get(tblName).get == false) {
            println("[INFO] First execute for table " + tblName + "with condition " + condition)
            status += doEtlPerDate(df, condition, totalPath, config.orcCoalesce)
            persistStatus.put(tblName, true)
          } else {
            println("[INFO] More execute for table " + tblName + "with condition " + condition)
            val task = doEtlPerTbl(df, condition, totalPath, config.orcCoalesce)
            task.onComplete {
              case Success(result) =>
                println(s"result = $result")
              case Failure(e) =>
                println(e.getMessage)
                status += e.getMessage
            }
            tasks += task
          }
        }

        end_time = yesterday
      }
    }
    Await.ready(Future.sequence(tasks), Duration(30, DAYS))
    println("[INFO] All Jobs has completed and the informations are:")
    for (i <- 0 until status.length) {
      println("[INFO]" + status(i))
    }
    df.unpersist()
    tasks.clear()
    println("[INFO] All Jobs has completed")
    spark.close()
  }

/*
* doEtlPerDate
* 当前表第一次导orc文件时调用此方法，数据真正持久化
* */
  def doEtlPerDate(df: DataFrame, condition: String, outPath: String, orcCoalesce: Int): String = {
    var message = "[INFO] filter the dataframe : " + condition + " and write the orc file in " + outPath + " with orcCoalesce: " + orcCoalesce + " for first time Synchronous successfully!"
    println("[INFO] The final schema infomation is:")
    df.printSchema()
    println("[INFO] Start filter and write data to path:" + outPath)
    if (0 == orcCoalesce) {
      if (condition == null || condition.equals("")) {
        df.write.orc(outPath)
      } else {
        df.filter(condition).write.orc(outPath)
      }
    } else {
      if (condition == null || condition.equals("")) {
        df.coalesce(orcCoalesce).write.orc(outPath)
      } else {
        df.filter(condition).coalesce(orcCoalesce).write.orc(outPath)
      }
    }
    message
  }


  def doEtlPerTbl(df: DataFrame, condition: String, outPath: String, orcCoalesce: Int)(implicit xc: ExecutionContext) = Future {
    var message = "[INFO] filter the dataframe : " + condition + " and write the orc file in " + outPath + " with orcCoalesce: " + orcCoalesce + " asynchronous successfully!"
    println("[INFO] The final schema infomation is:")
    df.printSchema()
    println("[INFO] Start filter and write data to path:" + outPath)
    if (0 == orcCoalesce) {
      if (condition == null || condition.equals("")) {
        df.write.orc(outPath)
      } else {
        df.filter(condition).write.orc(outPath)
      }
    } else {
      if (condition == null || condition.equals("")) {
        df.coalesce(orcCoalesce).write.orc(outPath)
      } else {
        df.filter(condition).coalesce(orcCoalesce).write.orc(outPath)
      }
    }
    message
  }

}
